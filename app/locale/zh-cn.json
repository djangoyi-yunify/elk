{
  "Name": "名称",
  "Description": "描述",
  "The name of the ELK service": "ELK 服务名称",
  "The description of the ELK service": "ELK 服务描述",
  "VxNet": "私有网络",
  "Choose a vxnet to join": "选择要加入的私有网络",
  "Express Configuration": "快速配置",
  "Test": "测试环境",
  "Pre-prod": "预生产环境",
  "Prod HA": "高可用生产环境",
  "Test: ES * 2, Logstash * 1, Kibana * 1; Pre-prod: ES * 2, ES M * 1, Logstash * 1, Kibana * 1; Prod HA: ES * 3, ES Master * 3, Logstash * 1, Kibana * 2": "测试环境：ES 节点 * 2，Logstash 节点 * 1，Kibana 节点 * 1；预生产环境：ES 节点 * 2，ES 专有主节点 * 1，Logstash 节点 * 1，Kibana 节点 * 1；高可用生产环境：ES 节点 * 3，ES 专有主节点 * 3，Logstash 节点 * 1，Kibana 节点 * 2",
  "CPU": "CPU",
  "CPUs of each node": "每个节点的 CPU 数量",
  "Memory": "内存",
  "Memory of each node": "每个节点的内存数量",
  "Instance Class": "主机类型",
  "Elasticsearch Node": "Elasticsearch 节点（热）",
  "Elasticsearch Node 2": "Elasticsearch 节点（温）",
  "Elasticsearch Node 3": "Elasticsearch 节点（冷）",
  "node.attr.data": "node.attr.data（热）",
  "node.attr.data (#2)": "node.attr.data（温）",
  "node.attr.data (#3)": "node.attr.data（冷）",
  "Custom attribute for ES node": "ES 节点自定义标签（node.attr.data），可用作热-温-冷架构配置",
  "ES node group can be used to hold hot-warm-cold data by label node.attr.data": "可以用来支持 热-温-冷（Hot-Warm-Cold）数据节点分离架构，这是在日志或监控领域常见的一种架构，详情可参考官方介绍：https://www.elastic.co/blog/implementing-hot-warm-cold-in-elasticsearch-with-index-lifecycle-management",
  "es_master_node": "Elasticsearch 专有主节点",
  "restart_rolling": "滚动重启",
  "dump": "生成 Heap Dump",
  "clear_dump": "清除 Heap Dump",
  "lst_node": "Logstash 节点",
  "kbn_node": "Kibana 节点",
  "esvip": "Elasticsearch VIP",
  "Kibana Node": "Kibana 节点",
  "Number of Kibana nodes to create": "要创建的 Kibana 节点数量，除了 Kibana 服务还绑定 VIP 并提供 Elasticsearch 的负载均衡和故障转移能力，建议创建至少一个节点并通过 VIP 访问 Elasticsearch（http://<ES VIP>:9200）；单节点 VIP 有单点失败的风险，如有需要可在此处创建两个节点保证 VIP 的高可用；如不创建 Kibana 节点将无法使用 ES VIP，只能通过 Elasticsearch 节点的 IP 访问",
  "Logstash Node": "Logstash 节点",
  "Node Count": "节点数量",
  "count": "次",
  "esnode_count": "个",
  "Number of nodes for the cluster to create": "要创建的节点数量",
  "Number of ES nodes to create": "要创建的 ES 节点数量，建议选择不少于分片副本数的个数来保证副本都能正常分配；建议配合专有主节点保证集群服务的高可用",
  "Volume Size": "存储容量",
  "The volume size for each ES node": "每个节点的存储容量，ES 数据节点挂载了三块硬盘以提高读写速度，三块硬盘容量平均分配，所以在此请选择 30G 的倍数；如果选择的是 NeonSAN，在此请选择 300G 的倍数",
  "The volume size for each node": "每个节点的存储容量",
  "Volume Class": "存储类型",
  "The volume type for each instance, such as high performance, high performance plus":"磁盘类型，比如性能型与超高性能型",
  "The volume type for each node, such as high performance, high performance plus": "每个节点的数据盘类型，性能型或超高性能型最大支持 2T 容量",
  "The volume type for each node, such as high performance, high performance plus, NeonSAN": "每个节点的数据盘类型，性能型或超高性能型最大支持 2T 容量，有大容量需要的用户可以选企业型 NeonSAN 大容量盘（NeonSAN 只有 北京3区-B、上海1区-A、广东2区-A 等部分区域支持，如上面没列出 NeonSAN 的选项，则说明该区域不支持）",
  "The instance type for the cluster to run, such as high performance, high performance plus": "节点主机的类型",
  "instance class": "实例类型",
  "Elasticsearch Master Node": "Elasticsearch 专有主节点",
  "Number of ES master nodes to create": "要创建的 ES 专有主节点数量，单节点仅供测试使用，生产环境请选择至少三节点；大规模集群（ES 节点数 ≥ 10）建议使用专有主节点来保证集群的高可用；如选择创建专有主节点，上面的 ES 节点将只承担数据功能（Data Node）；如选择不创建专有主节点，上面的 ES 节点将同时承担主节点的任务，可参阅官方文档查看详情：https://www.elastic.co/guide/en/elasticsearch/reference/6.7/modules-node.html",
  "ES Node IP": "ES 节点 IP",
  "The node IP of ES on which to dump JVM heap": "注意：此操作不可取消并会导致 ES 服务不可用直至 Dump 完成，可能会有数分钟甚至数十分钟停顿，请谨慎操作！此处填写要生成 Heap Dump 文件的 ES 节点 IP，请确保此 IP 是选中的角色里的一个节点，否则操作将被忽略；操作完成后可通过访问 http://IP/dump/ 获取",
  "Operation Timeout": "最大等待时间",
  "The dump timeout in seconds": "dump 操作最大等待时间，以秒为单位；如超过此时间仍未完成，将强制停止此操作（已生成的文件片段将保留）",
  "The node IP of ES on which to clear dump JVM heap": "此处填写要清除 Heap Dump 文件的 ES 节点 IP，请确保此 IP 是选中的角色里的一个节点，否则操作将被忽略；若不填则表示清除所有同角色节点上的 Dump 文件；操作完成后可通过访问 http://IP/dump/ 确认",
  "The node IP of ES on which to restart": "此处填写要重启的 ES 节点 IP，请确保此 IP 是选中的角色里的一个节点，否则操作将被忽略；若不填则表示重启所有同角色节点上的 ES 服务",
  "The restart timeout in seconds": "所有节点重启完成最大等待时间，以秒为单位；本操作每次只重启一个所选中角色的节点（以节点 IP 升序排列），并等待被重启节点所有分片加载完毕后再重启下一个；比如 600 秒表示若总共重启时间超过 10 分钟将停止操作，请结合日志自行检查重启结果；日志文件可以通过 http://IP/logs 访问",
  "The discovery.zen.no_master_block settings controls what operations should be rejected when there is no active master.": "控制当节点没有活跃的master节点时哪些操作应该被拒绝",
  "If the expected number of nodes is not achieved, the recovery process waits for the configured amount of time before trying to recover regardless. Defaults to 5m if one of the expected_nodes settings is configured.": "如果未达到期望的节点数,recovery过程将在配置的时间后开始recover操作,默认5分钟",
  "Enable or disable cross-origin resource sharing, i.e. whether a browser on another origin can execute requests against Elasticsearch.": "启用或禁用跨域资源共享，注意：此选项设置不当会有安全风险，详情请参阅官方文档 https://www.elastic.co/guide/en/elasticsearch/reference/6.7/modules-http.html",
  "Which origins to allow.": "允许跨域资源共享的域，注意：此选项设置不当会有安全风险，详情请参阅官方文档 https://www.elastic.co/guide/en/elasticsearch/reference/6.7/modules-http.html",
  "Controls the memory size for the filter cache , defaults to 10%. Accepts either a percentage value, like 5%, or an exact value, like 512mb.": "控制filter缓存的内存大小,默认10%,接受百分比值,如5%,或精确值,如512mb",
  "Accepts either a percentage or a byte size value. It defaults to 10%, meaning that 10% of the total heap allocated to a node will be used as the indexing buffer size shared across all shards.": "接受百分比值或字节值.默认10%,意味着总堆内存的10%将被用于索引缓存被所有分片共享",
  "The shard-level request cache module caches the local results on each shard. The cache is managed at the node level, and has a default maximum size of 1% of the heap.": "分片级的请求缓存对每一个分片做本地缓存.这个缓存在节点级进行管理,默认堆内存的1%",
  "Remote hosts for 'reindex' operation have to be explicitly whitelisted in elasticsearch.yaml using the reindex.remote.whitelist property. It can be set to a comma delimited list of allowed remote host and port combinations (e.g. otherhost:9200, another:9200, 127.0.10.*:9200, localhost:*)": "用来 reindex 操作的远程 ES 节点需要加入白名单，多个 ES 节点可以由半角逗号分隔，如：otherhost:9200, 192.168.1.*:9200, localhost:*，详情可参考官方文件：https://www.elastic.co/guide/en/elasticsearch/reference/5.6/docs-reindex.html#reindex-from-remote",
  "Specify whether scripts with inline type are allowed.": "指定inline类型的脚本是否被允许",
  "Specify whether scripts with stored type are allowed.": "指定stored类型的脚本是否被允许",
  "Specify whether scripts with file type are allowed.": "指定file类型的脚本是否被允许",
  "Specify whether scripts can be executed in aggregations context.": "指定脚本是否可在aggregations上下文中执行",
  "Specify whether scripts can be executed in search context.": "指定脚本是否可在search上下文中执行",
  "Specify whether scripts can be executed in update context.": "指定脚本是否可在update上下文中执行",
  "the interval between subsequent keepalive probes, regardless of what the connection has exchanged in the meantime": "TCP keepalive 探活的时间间隔（一般保持默认即可）",
  "the number of unacknowledged probes to send before considering the connection dead and notifying the application layer": "在通知应用层连接断开之前，允许尝试发送未应答的（unacknowledged）探活请求的数量（一般保持默认即可）",
  "the interval between the last data packet sent (simple ACKs are not considered data) and the first keepalive probe; after the connection is marked to need keepalive, this counter is not used any further": "最后一次发送数据包之后，到发送第一个 keepalive 保活请求之间的时间间隔（一般保持默认即可）",
  "When you run logstash, you use the -f to specify your config file, and this config is what your config file contained in input section": "当你执行logstash,你用-f指定你的配置文件,你的配置文件的input段的内容将由此设置项决定",
  "When you run logstash, you use the -f to specify your config file, and this config is what your config file contained in filter section": "当你执行logstash,你用-f指定你的配置文件,你的配置文件的filter段的内容将由此设置项决定",
  "When you run logstash, you use the -f to specify your config file, and this config is what your config file contained in output section": "当你执行logstash,你用-f指定你的配置文件,你的配置文件的output段的内容将由此设置项决定",
  "When you run logstash, you use the -f to specify your config file, and this config is what your config file contained in output elasticsearch section": "当你执行logstash,你用-f指定你的配置文件,你的配置文件的output段中的elasticsearch段的内容将由此设置项决定",
  "Specify the location of extensional dictionary from remote.": "指定扩展字典的远程位置",
  "Specify the location of extensional stopwords dictionary from remote.": "指定扩展停止词字典的远程位置",
  "This config is used to adding content into Gemfile for logstash": "本设置项用于为logstash的Gemfile文件增加内容",
  "cluster_status": "集群健康状态",
  "number_of_nodes": "节点数",
  "cluster_jvm_heap_used_in_percent": "集群JVM堆内存使用百分比",
  "cluster_jvm_threads_count": "集群JVM线程数",
  "relocating_shards": "正在迁移的分片数",
  "unassigned_shards": "未分配的分片数",
  "number_of_pending_tasks": "等待中的任务数",
  "number_of_in_flight_fetch": "执行中的fetch数",
  "task_max_waiting_in_queue_millis": "任务在队列中的最大等待时间",
  "active_shards_percent_as_number": "活跃分片百分比",
  "cluster_indices_count": "集群索引数",
  "cluster_docs_group": "集群文档监控组",
  "cluster_docs_count": "集群文档数",
  "cluster_docs_deleted_count": "集群已删除文档数",
  "cluster_shards_group": "集群分片监控组",
  "cluster_shards_primaries_count": "集群主分片数",
  "cluster_shards_replication_count": "集群副本分片数",
  "initializing_shards": "初始化中的分片数",
  "Whether to enable elasticsearch-head.": "是否启用elasticsearch-head，启用前请先设置 ES 节点的 http.cors.enabled 为 true 并设置合适的 http.cors.allow-origin",
  "Whether to enable ElasticHD.": "是否启用ElasticHD",
  "Whether to enable Cerebro.": "是否启用Cerebro",
  "Whether to enable elasticsearch-hq.": "是否启用Elasticsearch-HQ",
  "Whether to enable elasticsearch-sql.": "是否启用elasticsearch-sql",
  "In order to enable allowing to delete indices via wildcards or _all, set this config to false.": "为了允许在删除索引时使用通配符或_all, 请设置此配置项为false",
  "The max size of the field data cache.": "field缓存数据所能使用的堆内存的最大值",
  "Specify the location of shared file system repository.": "指定共享文件系统仓库的位置",
  "Specify the location of read-only URL repository.": "指定只读URL仓库的位置",
  "The additional configuration in elasticsearch.yml.": "elasticsearch.yml中的附加配置",
  "Periodically check if the configuration has changed and reload the pipeline. This can also be triggered manually through the SIGHUP signal": "定期检查配置文件并自动加载更改过的 pipeline 配置",
  "How often to check if the pipeline configuration has changed (in seconds)": "定期检查配置文件的频率，以秒为单位",
  "Mapping type": "映射类型（mapping types）",
  "ES Proxy Balance Policy": "ES 代理负载均衡策略",
  "Define the load balancing algorithm to be used in a backend": "选项详细说明请查阅官方文档：https://cbonte.github.io/haproxy-dconv/1.8/configuration.html#4-balance",
  "ES Proxy Connect Timeout": "ES 代理连接超时时间",
  "Sets the timeout for HAProxy to connect ES services, can be ms, s, m, or h, e.g. 50s for 50 seconds": "HAProxy 连接后端 ES 服务的超时时间，时间单位可以是 ms（毫秒）、s（秒）、m（分）或者 h（小时），比如 50s 表示 50 秒",
  "ES Proxy Timeout": "ES 代理超时时间",
  "Sets the timeout for HAProxy to get response from ES services, can be ms, s, m, or h, e.g. 50s for 50 seconds": "HAProxy 等待后端 ES 服务返回响应的超时时间，时间单位可以是 ms（毫秒）、s（秒）、m（分）或者 h（小时），比如 50s 表示 50 秒",
  "ES Proxy Max Connections": "ES 代理最大连接数",
  "Sets the maximum per-process number of concurrent connections": "最大并发连接数，超出的客户端连接请求将排队等待，详情请参阅官方文档：https://cbonte.github.io/haproxy-dconv/1.8/configuration.html#4-maxconn",
  "ES Proxy Max Request": "ES 代理最大请求体",
  "Sets the maximum allowed size of the client request body": "设置 ES 代理的客户端请求体的最大允许值，以 MB 为单位，比如 20m 表示最大允许 20m 字节",
  "Enables you to specify a path to mount Kibana at if you are running behind a proxy. Use the server.rewriteBasePath setting to tell Kibana if it should remove the basePath from requests it receives, and to prevent a deprecation warning at startup. This setting cannot end in a slash (/).": "需要在 Kibana 前面加一层代理时，可以通过此参数设置 Kibana 的路径，不能以斜线（/）结尾，详情可参考官方文档：https://www.elastic.co/guide/en/kibana/master/settings.html",
  "Specifies whether Kibana should rewrite requests that are prefixed with server.basePath or require that they are rewritten by your reverse proxy": "是否重写 bashPath，详情可参考官方文档：https://www.elastic.co/guide/en/kibana/master/settings.html",
  "The logger.action.level configuration in log4j2.properties.": "日志配置文件log4j2.properties中的logger.action.level配置项",
  "The rootLogger.level configuration in log4j2.properties.": "日志配置文件log4j2.properties中的rootLogger.level配置项",
  "The logger.deprecation.level configuration in log4j2.properties.": "日志配置文件log4j2.properties中的logger.deprecation.level配置项",
  "The logger.index_search_slowlog_rolling.level configuration in log4j2.properties.": "日志配置文件log4j2.properties中的logger.index_search_slowlog_rolling.level配置项",
  "The logger.index_indexing_slowlog.level configuration in log4j2.properties.": "日志配置文件log4j2.properties中的logger.index_indexing_slowlog.level配置项",
  "Whether to enable heap dump on out of memory error.": "是否启用自动 heap dump",
  "The path of heap dump.": "Heap dump 文件的存储路径",
  "Clean logs older than n days, n can be changed here.": "清理老于n天的日志，n可以在这里配置",
  "err_code1": "待删除节点上的数据未成功迁移到其他节点,请手动迁移或通过工单与我们联系"
}
